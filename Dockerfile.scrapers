FROM python:3.11-slim

# Install system dependencies for web scraping, PDF processing, and browser automation
RUN apt-get update && apt-get install -y \
    curl \
    wget \
    gcc \
    g++ \
    gnupg \
    ca-certificates \
    xvfb \
    tesseract-ocr \
    tesseract-ocr-eng \
    poppler-utils \
    && rm -rf /var/lib/apt/lists/*

# Install Google Chrome for better stealth than Chromium
RUN wget -q -O - https://dl.google.com/linux/linux_signing_key.pub | apt-key add - \
    && echo "deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main" >> /etc/apt/sources.list.d/google-chrome.list \
    && apt-get update \
    && apt-get install -y google-chrome-stable \
    && rm -rf /var/lib/apt/lists/*

# Set working directory
WORKDIR /app

# Copy requirements and install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Install Patchright (undetected Playwright replacement)
RUN patchright install chromium

# Copy scraper code
COPY src/ ./src/

# Create non-root user
RUN useradd -m -u 1000 scraperuser && chown -R scraperuser:scraperuser /app
USER scraperuser

# Create directories for permits and logs
RUN mkdir -p /app/logs /app/data /app/data/permits

# Start scraper services with virtual display for headed mode
CMD ["xvfb-run", "-a", "--server-args=-screen 0 1920x1080x24", "python", "-m", "src.scrapers.scheduler"]